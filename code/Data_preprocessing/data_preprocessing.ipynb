{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_solomon_data(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        if \"VEHICLE\" in line:\n",
    "            vehicle_line = lines[i + 2]\n",
    "            break\n",
    "\n",
    "    vehicle_number_line = vehicle_line.split()\n",
    "    vehicle_number = int(vehicle_number_line[0])\n",
    "    vehicle_capacity = int(vehicle_number_line[1])\n",
    "    vehicle_capacitiesLB = [vehicle_capacity] * vehicle_number\n",
    "\n",
    "    demandLB = []\n",
    "    time_windows = []\n",
    "    coords = []\n",
    "    due_time_0 = 0\n",
    "\n",
    "    for line in lines[i + 4:]:\n",
    "        parts = line.split()\n",
    "        if len(parts) == 7:\n",
    "            customer_id = int(parts[0])\n",
    "            x_coord = int(parts[1])\n",
    "            y_coord = int(parts[2])\n",
    "            demand = int(parts[3])\n",
    "            ready_time = int(parts[4])\n",
    "            due_time = int(parts[5])\n",
    "            service_time = int(parts[6])\n",
    "\n",
    "            if customer_id == 0:\n",
    "                due_time_0 = due_time\n",
    "            demandLB.append(demand)\n",
    "            time_windows.append((ready_time, due_time))\n",
    "            coords.append((x_coord, y_coord))\n",
    "\n",
    "    return vehicle_number, vehicle_capacity\n",
    "    # return vehicle_number, vehicle_capacitiesLB, demandLB, time_windows, coords, service_time, due_time_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(input_file):\n",
    "    with open(input_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    processed_lines = []\n",
    "    for line in lines:\n",
    "        # 保留换行符后，去掉每行中的多余空格，将多个空格替换为一个空格\n",
    "        # After retaining the newline character, remove the extra Spaces in each line and replace multiple Spaces with one space\n",
    "        line = re.sub(r'\\s+', ' ', line.strip())  # After removing the first and last Spaces, replace the multiple Spaces in the middle\n",
    "        \n",
    "        # Restore the line break character\n",
    "        line = line + '\\n'\n",
    "\n",
    "        if \"READY TIME DUE DATE SERVICE TIME\" in line:\n",
    "            line = line.replace('READY TIME DUE DATE SERVICE TIME', 'READY_TIME DUE_DATE SERVICE_TIME')\n",
    "\n",
    "        # Add the processed rows to the list\n",
    "        processed_lines.append(line)\n",
    "\n",
    "    processed_text = ''.join(processed_lines)\n",
    "\n",
    "    # Print out the complete text\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# Path setting\n",
    "save_path = \"/home/wsl/CVRPTW/data/routes_distance_200\"\n",
    "\n",
    "# Store the last run_time of each file\n",
    "last_run_times = []\n",
    "\n",
    "# Confirm whether save_path exists and is a folder\n",
    "if not os.path.exists(save_path) or not os.path.isdir(save_path):\n",
    "    print(f\"Error: {save_path} is not a valid directory.\")\n",
    "else:\n",
    "    # Traverse the files in the \"result\" folder\n",
    "    for file_name in os.listdir(save_path):\n",
    "        result_file_path = os.path.join(save_path, file_name)\n",
    "\n",
    "        # Only handle files ending with _results.txt\n",
    "        if file_name.endswith(\"_results.txt\"):\n",
    "            try:\n",
    "                with open(result_file_path, 'r') as result_file:\n",
    "                    lines = [line.strip() for line in result_file.readlines() if line.strip()]\n",
    "\n",
    "                # Make sure there are at least three lines of data\n",
    "                if len(lines) >= 3:\n",
    "                    # Obtain the last group of three lines of data\n",
    "                    run_time_line = lines[-3]\n",
    "\n",
    "                    # Extract the value of run_time\n",
    "                    run_time = int(run_time_line.split(\":\")[1].strip())\n",
    "                    last_run_times.append(run_time)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file_name}: {e}\")\n",
    "\n",
    "# Count the occurrence times of run_time\n",
    "run_time_counts = Counter(last_run_times)\n",
    "\n",
    "# Print the result\n",
    "for run_time, count in run_time_counts.items():\n",
    "    print(f\"run_time {run_time} appears {count} times\")\n",
    "\n",
    "# Draw the histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(last_run_times, bins=range(min(last_run_times), max(last_run_times) + 1), color='blue', alpha=0.7, edgecolor='black')\n",
    "plt.xlabel(\"Run Time\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Ortools high_quality solution run time of Solomon100\")\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Read the result_distance.xlsx file\n",
    "result_distance_df = pd.read_excel(\"/home/wsl/CVRPTW/result_distance.xlsx\")\n",
    "result_distance_dict = dict(zip(result_distance_df['file_name'], result_distance_df['distance']))\n",
    "\n",
    "result_split_path = \"/home/wsl/CVRPTW/data/result_single_0406\"\n",
    "result_path = \"/home/wsl/CVRPTW/data/result_single_0406\"\n",
    "origine_data_path = \"/home/wsl/CVRPTW/data/origine data/solomon_100\"\n",
    "best_solution_route_path = \"/home/wsl/CVRPTW/data/best_solution_route\"\n",
    "\n",
    "customer_number = 100\n",
    "\n",
    "all_conversations = []\n",
    "\n",
    "for file_name in os.listdir(best_solution_route_path):\n",
    "    if file_name.endswith(\".txt\"):\n",
    "        print(f\"Processing file: {file_name}\")\n",
    "\n",
    "        file_name_without_extension = file_name.replace('.txt', '')\n",
    "        file_link = os.path.join(origine_data_path, f\"{file_name_without_extension}.txt\")\n",
    "\n",
    "        file_content = process_text(file_link)\n",
    "\n",
    "        vehicle_number, vehicle_capacity = load_solomon_data(file_link)\n",
    "\n",
    "        total_distance = result_distance_dict.get(file_name_without_extension, None)\n",
    "\n",
    "        try:\n",
    "            with open(os.path.join(best_solution_route_path, file_name), 'r') as best_solution_file:\n",
    "                all_routes_versions = [line.strip() for line in best_solution_file.readlines() if line.strip()]\n",
    "                all_routes_list = [json.loads(route) for route in all_routes_versions]\n",
    "\n",
    "            file_conversations = []\n",
    "\n",
    "            for all_routes in all_routes_list:\n",
    "                gpt_value = json.dumps(all_routes)\n",
    "                human_value = f\"\"\"Data: {file_content}; \\n Data explanation: There is a starting point (CUST NO.==0) and {customer_number} customer points. All constants are integers. VEHICLE NUMBER is {vehicle_number}, which means the maximum number of vehicles that can be dispatched. CAPACITY is {vehicle_capacity}, which means the maximum load of each vehicle. XCOORD and YCOORF are the horizontal and vertical coordinates of the starting point and the customer point. For the convenience of calculation, the distance between nodes is regarded as the transportation cost between nodes. DEMAND is the demand at the node, and the demand at the starting point depot is 0. READY_TIME indicates the earliest start time of the service at the starting point and the customer point. DUE_TIME indicates the service deadline. For the starting point, this value indicates the latest time when all vehicles must return. SERVICE_TIME indicates the longest duration of service at each node.\\n The simple restrictions on the initial solution are that the number of running vehicles is less than or equal to {vehicle_number}, that is, at most {vehicle_number}; each running vehicle starts from 0 and eventually returns to 0, that is, the data of each running vehicle in initial_solution should be [0,...,0]; all of 1 to {customer_number} customer points must be served, that means your output must include all of 1 to {customer_number} numbers, and these {customer_number} numbers from 1 to {customer_number} cannot be repeated.\n",
    "The output must adhere strictly to the following constraints:\n",
    "1. The total number of elements (excluding 0) **must be exactly** {customer_number}. There should be no fewer or greater numbers in the output.\n",
    "2. The list of numbers must include every integer from **1 to {customer_number}**, without any omissions. This means that the sequence **must** contain all of the numbers from 1 through {customer_number}, and no number should be left out.\n",
    "3. No number from 1 to {customer_number} should appear more than once. **All numbers must be unique**. Repeated numbers are strictly prohibited and must not appear in the output.\n",
    "4. If any number is repeated, **exclude** it from the output entirely and make sure that the list still includes **all numbers from 1 to {customer_number}** without repetition.\n",
    "**Important**: The sequence should only contain unique integers from 1 to {customer_number}. If any duplicate is found, the output should be considered invalid and corrected to meet the exact requirements. This means the model must enforce strict uniqueness and must never allow any duplicates in the list.\"\"\"  # 可以根据需要自定义 human_value\n",
    "\n",
    "                conversation = {\n",
    "                    \"conversations\": [\n",
    "                        {\n",
    "                            \"from\": \"human\",\n",
    "                            \"value\": human_value\n",
    "                        },\n",
    "                        {\n",
    "                            \"from\": \"gpt\",\n",
    "                            \"value\": gpt_value\n",
    "                        }\n",
    "                    ],\n",
    "                    \"system\": \"You are an expert in solving Capacitated Vehicle Routing Problem with Time Windows (CVRPTW) problems. You can output the best initial solution based on the CVRPTW data I provided to make total_distance as small as possible. Do not output any text other than the initial solution. The format example is: [[0, xxx,xxx, 0], [0, xxx, xxx,xxx,xxx, xxx, xxx, 0], ...,[0, xxx,xxx, xxx,0]]. I hope you can strictly follow my output format and element requirements.\"  # 系统消息内容\n",
    "                }\n",
    "\n",
    "                file_conversations.append(conversation)\n",
    "\n",
    "            all_conversations.extend(file_conversations)\n",
    "\n",
    "            output_json_path_file = os.path.join(result_split_path, f\"conversations_output_{file_name}.json\")\n",
    "            with open(output_json_path_file, 'w') as json_file:\n",
    "                json.dump(file_conversations, json_file, indent=4)\n",
    "\n",
    "            print(f\"Conversation for {file_name} has been saved to '{output_json_path_file}'\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_name}: {e}\")\n",
    "\n",
    "output_json_path = os.path.join(result_path, \"conversations_output_single_100_0404.json\")\n",
    "with open(output_json_path, 'w') as json_file:\n",
    "    json.dump(all_conversations, json_file, indent=4)\n",
    "print(f\"All conversations have been saved to '{output_json_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/home/wsl/CVRPTW/data/result_route_0402/c\"\n",
    "result_split_path = \"/home/wsl/CVRPTW/data/result_single_0404_1\"\n",
    "result_path = \"/home/wsl/CVRPTW/data/merge_result_single_0404_1\"\n",
    "origine_data_path = \"/home/wsl/CVRPTW/data/origine data/solomon_100\"\n",
    "\n",
    "customer_number = 100\n",
    "\n",
    "all_conversations = []\n",
    "\n",
    "if not os.path.exists(save_path) or not os.path.isdir(save_path):\n",
    "    print(f\"Error: {save_path} is not a valid directory.\")\n",
    "else:\n",
    "    for file_name in os.listdir(save_path):\n",
    "        result_file_path = os.path.join(save_path, file_name)\n",
    "\n",
    "        if file_name.endswith(\"_results.txt\"):\n",
    "            print(f\"Processing file: {result_file_path}\")\n",
    "\n",
    "            base_name = os.path.basename(result_file_path)\n",
    "\n",
    "            file_name_without_results = base_name.replace('_results.txt', '')\n",
    "\n",
    "            file_link = os.path.join(origine_data_path, file_name_without_results)\n",
    "            file_content = process_text(file_link)\n",
    "\n",
    "            vehicle_number, vehicle_capacity = load_solomon_data(file_link)\n",
    "\n",
    "\n",
    "            try:\n",
    "                with open(result_file_path, 'r') as result_file:\n",
    "                    lines = [line for line in result_file.readlines() if line.strip()]\n",
    "\n",
    "                file_conversations = []\n",
    "\n",
    "                for i in range(0, len(lines), 3):\n",
    "                    if i + 2 < len(lines):  \n",
    "                        run_time_line = lines[i].strip()\n",
    "                        all_routes_line = lines[i + 1].strip()\n",
    "                        total_distance_line = lines[i + 2].strip()\n",
    "\n",
    "                        try:\n",
    "                            run_time = int(run_time_line.split(\":\")[1].strip())\n",
    "                            all_routes = json.loads(all_routes_line.split(\":\")[1].strip())\n",
    "                            total_distance = float(total_distance_line.split(\":\")[1].strip())\n",
    "\n",
    "                            gpt_value = json.dumps(all_routes)\n",
    "                            human_value = f\"\"\"Data: {file_content}; \\n Data explanation: There is a starting point (CUST NO.==0) and {customer_number} customer points. All constants are integers. VEHICLE NUMBER is {vehicle_number}, which means the maximum number of vehicles that can be dispatched. CAPACITY is {vehicle_capacity}, which means the maximum load of each vehicle. XCOORD and YCOORF are the horizontal and vertical coordinates of the starting point and the customer point. For the convenience of calculation, the distance between nodes is regarded as the transportation cost between nodes. DEMAND is the demand at the node, and the demand at the starting point depot is 0. READY_TIME indicates the earliest start time of the service at the starting point and the customer point. DUE_TIME indicates the service deadline. For the starting point, this value indicates the latest time when all vehicles must return. SERVICE_TIME indicates the longest duration of service at each node.\\n The simple restrictions on the initial solution are that the number of running vehicles is less than or equal to {vehicle_number}, that is, at most {vehicle_number}; each running vehicle starts from 0 and eventually returns to 0, that is, the data of each running vehicle in initial_solution should be [0,...,0]; all of 1 to {customer_number} customer points must be served, that means your output must include all of 1 to {customer_number} numbers, and these {customer_number} numbers from 1 to {customer_number} cannot be repeated.\n",
    "The output must adhere strictly to the following constraints:\n",
    "1. The total number of elements (excluding 0) **must be exactly** {customer_number}. There should be no fewer or greater numbers in the output.\n",
    "2. The list of numbers must include every integer from **1 to {customer_number}**, without any omissions. This means that the sequence **must** contain all of the numbers from 1 through {customer_number}, and no number should be left out.\n",
    "3. No number from 1 to {customer_number} should appear more than once. **All numbers must be unique**. Repeated numbers are strictly prohibited and must not appear in the output.\n",
    "4. If any number is repeated, **exclude** it from the output entirely and make sure that the list still includes **all numbers from 1 to {customer_number}** without repetition.\n",
    "**Important**: The sequence should only contain unique integers from 1 to {customer_number}. If any duplicate is found, the output should be considered invalid and corrected to meet the exact requirements. This means the model must enforce strict uniqueness and must never allow any duplicates in the list.\"\"\"\n",
    "\n",
    "                            conversation = {\n",
    "                                \"conversations\": [\n",
    "                                    {\n",
    "                                        \"from\": \"human\",\n",
    "                                        \"value\": human_value\n",
    "                                    },\n",
    "                                    {\n",
    "                                        \"from\": \"gpt\",\n",
    "                                        \"value\": gpt_value\n",
    "                                    }\n",
    "                                ],\n",
    "                                \"system\": \"You are an expert in solving Capacitated Vehicle Routing Problem with Time Windows (CVRPTW) problems. You can output the best initial solution based on the CVRPTW data I provided to make total_distance as small as possible. Do not output any text other than the initial solution. The format example is: [[0, xxx,xxx, 0], [0, xxx, xxx,xxx,xxx, xxx, xxx, 0], ...,[0, xxx,xxx, xxx,0]]. I hope you can strictly follow my output format and element requirements.\"  # 系统消息内容，可以根据需要调整\n",
    "                            }\n",
    "\n",
    "                            file_conversations.append(conversation)\n",
    "\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error parsing run_time or total_distance in {result_file_path}: {e}\")\n",
    "\n",
    "                all_conversations.extend(file_conversations)\n",
    "\n",
    "                output_json_path_file = os.path.join(result_split_path, f\"conversations_output_{file_name}.json\")\n",
    "                with open(output_json_path_file, 'w') as json_file:\n",
    "                    json.dump(file_conversations, json_file, indent=4)\n",
    "\n",
    "                print(f\"Conversation for {file_name} has been saved to '{output_json_path_file}'\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {result_file_path}: {e}\")\n",
    "\n",
    "    output_json_path = os.path.join(result_path, \"conversations_output_single_100_0404.json\")\n",
    "    with open(output_json_path, 'w') as json_file:\n",
    "        json.dump(all_conversations, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/home/wsl/CVRPTW/data/result_route_processed_0404\"\n",
    "result_split_path = \"/home/wsl/CVRPTW/data/result_multi_0404\"\n",
    "result_path = \"/home/wsl/CVRPTW/data/merge_result_multi_0404\"\n",
    "origine_data_path = \"/home/wsl/CVRPTW/data/origine data/solomon_100\"\n",
    "       \n",
    "customer_number = 100\n",
    "\n",
    "all_conversations = []\n",
    "\n",
    "if not os.path.exists(save_path) or not os.path.isdir(save_path):\n",
    "    print(f\"Error: {save_path} is not a valid directory.\")\n",
    "else:\n",
    "    for file_name in os.listdir(save_path):\n",
    "        result_file_path = os.path.join(save_path, file_name)\n",
    "\n",
    "        if file_name.endswith(\"_results.txt\"):\n",
    "            print(f\"Processing file: {result_file_path}\")\n",
    "\n",
    "            base_name = os.path.basename(result_file_path)\n",
    "\n",
    "            file_name_without_results = base_name.replace('_results.txt', '')\n",
    "\n",
    "            file_link = os.path.join(origine_data_path, file_name_without_results)\n",
    "            file_content = process_text(file_link)\n",
    "\n",
    "            vehicle_number, vehicle_capacity = load_solomon_data(file_link)\n",
    "\n",
    "\n",
    "            try:\n",
    "                with open(result_file_path, 'r') as result_file:\n",
    "                    lines = [line for line in result_file.readlines() if line.strip()]\n",
    "\n",
    "                conversation = {\n",
    "                    \"conversations\": [],\n",
    "                    \"system\": (\n",
    "                        \"You are an expert in solving Capacitated Vehicle Routing Problem with Time Windows (CVRPTW) problems. You can output the best initial solution based on the CVRPTW data I provided to make total_distance as small as possible. Do not output any text other than the initial solution. The format example is: [[0, xxx,xxx, 0], [0, xxx, xxx,xxx,xxx, xxx, xxx, 0], ...,[0, xxx,xxx, xxx,0]]. I hope you can strictly follow my output format and element requirements.\"\n",
    "                    )\n",
    "                }\n",
    "\n",
    "                all_distance = []\n",
    "                j = 0\n",
    "                first_run_time = None \n",
    "                for i in range(0, len(lines), 3):\n",
    "                    if i + 2 < len(lines):  \n",
    "                        run_time_line = lines[i].strip()\n",
    "                        all_routes_line = lines[i + 1].strip()\n",
    "                        total_distance_line = lines[i + 2].strip()\n",
    "\n",
    "                        try:\n",
    "                            run_time = int(run_time_line.split(\":\")[1].strip())\n",
    "                            all_routes = json.loads(all_routes_line.split(\":\")[1].strip())\n",
    "                            total_distance = float(total_distance_line.split(\":\")[1].strip())\n",
    "                            all_distance.append(total_distance)\n",
    "                            print(all_distance)\n",
    "\n",
    "                            gpt_value = json.dumps(all_routes)\n",
    "\n",
    "                            if first_run_time is None:\n",
    "                                first_run_time = run_time\n",
    "\n",
    "                            if run_time == first_run_time:\n",
    "                                human_value = f\"\"\"Data: {file_content}; \\n Data explanation: There is a starting point (CUST NO.==0) and {customer_number} customer points. All constants are integers. VEHICLE NUMBER is {vehicle_number}, which means the maximum number of vehicles that can be dispatched. CAPACITY is {vehicle_capacity}, which means the maximum load of each vehicle. XCOORD and YCOORF are the horizontal and vertical coordinates of the starting point and the customer point. For the convenience of calculation, the distance between nodes is regarded as the transportation cost between nodes. DEMAND is the demand at the node, and the demand at the starting point depot is 0. READY_TIME indicates the earliest start time of the service at the starting point and the customer point. DUE_TIME indicates the service deadline. For the starting point, this value indicates the latest time when all vehicles must return. SERVICE_TIME indicates the longest duration of service at each node.\\n The simple restrictions on the initial solution are that the number of running vehicles is less than or equal to {vehicle_number}, that is, at most {vehicle_number}; each running vehicle starts from 0 and eventually returns to 0, that is, the data of each running vehicle in initial_solution should be [0,...,0]; all of 1 to {customer_number} customer points must be served, that means your output must include all of 1 to {customer_number} numbers, and these {customer_number} numbers from 1 to {customer_number} cannot be repeated.\n",
    "The output must adhere strictly to the following constraints:\n",
    "1. The total number of elements (excluding 0) **must be exactly** {customer_number}. There should be no fewer or greater numbers in the output.\n",
    "2. The list of numbers must include every integer from **1 to {customer_number}**, without any omissions. This means that the sequence **must** contain all of the numbers from 1 through {customer_number}, and no number should be left out.\n",
    "3. No number from 1 to {customer_number} should appear more than once. **All numbers must be unique**. Repeated numbers are strictly prohibited and must not appear in the output.\n",
    "4. If any number is repeated, **exclude** it from the output entirely and make sure that the list still includes **all numbers from 1 to {customer_number}** without repetition.\n",
    "**Important**: The sequence should only contain unique integers from 1 to {customer_number}. If any duplicate is found, the output should be considered invalid and corrected to meet the exact requirements. This means the model must enforce strict uniqueness and must never allow any duplicates in the list. \"\"\"\n",
    "                            else:\n",
    "                                human_value = f\"I used the initial solution you provided as input to the algorithm and the total_distance (best cost) that I got was {all_distance[j-1]}. Is there any initial solution that can get better results? Please continue to generate an initial solution that can get a sufficiently small total_distance.\"\n",
    "\n",
    "                            conversation[\"conversations\"].append({\n",
    "                                \"from\": \"human\",\n",
    "                                \"value\": human_value\n",
    "                            })\n",
    "\n",
    "                            \n",
    "                            conversation[\"conversations\"].append({\n",
    "                                \"from\": \"gpt\",\n",
    "                                \"value\": gpt_value \n",
    "                            })\n",
    "\n",
    "\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error parsing run_time or total_distance in {result_file_path}: {e}\")\n",
    "                        \n",
    "                        j += 1\n",
    "\n",
    "                conversation[\"conversations\"].append({\n",
    "                    \"from\": \"human\",\n",
    "                    \"value\": f\"Excellent! In the last round of dialogue, your output helped me get a high-quality solution for my algorithm, where the total_distance (best cost) that I got was {all_distance[j-1]}.\"\n",
    "                })\n",
    "\n",
    "                conversation[\"conversations\"].append({\n",
    "                    \"from\": \"gpt\",\n",
    "                    \"value\": \"Well, I will continue to consider the internal relationships of the data you provided and calculate a more high-quality solution.\"\n",
    "                })\n",
    "\n",
    "                all_conversations.append(conversation)\n",
    "\n",
    "                output_json_path_file = os.path.join(result_split_path, f\"conversations_output_multi_reset_{file_name}.json\")\n",
    "                with open(output_json_path_file, 'w') as json_file:\n",
    "                    json.dump(conversation, json_file, indent=4)\n",
    "\n",
    "                print(f\"Conversation for {file_name} has been saved to '{output_json_path_file}'\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {result_file_path}: {e}\")\n",
    "                \n",
    "    output_json_path = os.path.join(result_path, \"conversations_output_multi_100_0404.json\")\n",
    "    with open(output_json_path, 'w') as json_file:\n",
    "        json.dump(all_conversations, json_file, indent=4)\n",
    "\n",
    "    print(f\"All conversations have been saved to '{output_json_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "\n",
    "# 文件夹路径\n",
    "folder_path = \"/home/wsl/CVRPTW/data/best111\"\n",
    "\n",
    "# 遍历该路径中的所有文件\n",
    "for file_name in os.listdir(folder_path):\n",
    "    # 确保只处理 .txt 文件\n",
    "    if file_name.endswith(\".txt\"):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "        \n",
    "        try:\n",
    "            # 读取文件内容，假设文件内容是一个列表形式的 Route 数据\n",
    "            with open(file_path, 'r') as instance_file:\n",
    "                route_lists = json.load(instance_file)  # 从文件中读取数据\n",
    "\n",
    "            # 打乱生成不同版本并存储\n",
    "            all_permutations = set()\n",
    "            # 将原始的 route_lists 转为元组，以确保它是不可变的，可以存入集合中\n",
    "            all_permutations.add(tuple(tuple(route) for route in route_lists))  # 将每个 route 转为元组\n",
    "\n",
    "            # 打开文件进行写入，覆盖原文件内容\n",
    "            with open(file_path, 'w') as instance_file:\n",
    "                # 先存储原始顺序\n",
    "                json.dump(route_lists, instance_file)\n",
    "                instance_file.write('\\n\\n')  # 用换行隔开\n",
    "\n",
    "                # 打乱并生成多个版本\n",
    "                for _ in range(30):  # 限制最大打乱次数，避免无限打乱\n",
    "                    shuffled_routes = route_lists[:]  # 拷贝一份原始数据\n",
    "                    random.shuffle(shuffled_routes)  # 打乱\n",
    "                    # 将打乱后的版本转为不可变元组并确保唯一\n",
    "                    shuffled_tuple = tuple(tuple(route) for route in shuffled_routes)\n",
    "                    if shuffled_tuple not in all_permutations:\n",
    "                        all_permutations.add(shuffled_tuple)\n",
    "                        instance_file.write(json.dumps(shuffled_routes) + '\\n\\n')  # 存储打乱版本\n",
    "\n",
    "            print(f\"Processed file saved to: {file_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "result_distance_df = pd.read_excel(\"/home/wsl/CVRPTW/result_distance.xlsx\")\n",
    "result_distance_dict = dict(zip(result_distance_df['file_name'], result_distance_df['distance']))\n",
    "\n",
    "source_path = \"/home/wsl/CVRPTW/data/result_route_0402/c\" \n",
    "destination_path = \"/home/wsl/CVRPTW/data/result_route_processed\" \n",
    "best_solution_route_path = \"/home/wsl/CVRPTW/data/best_solution_route\"  \n",
    "\n",
    "os.makedirs(destination_path, exist_ok=True)\n",
    "\n",
    "for file_name in os.listdir(source_path):\n",
    "    if file_name.endswith(\"_results.txt\"):\n",
    "        print(f\"Processing file: {file_name}\")\n",
    "\n",
    "        result_file_path = os.path.join(source_path, file_name)\n",
    "        \n",
    "        file_name_without_extension = file_name.replace('.txt_results.txt', '').lower()\n",
    "\n",
    "        best_solution_file_path = os.path.join(best_solution_route_path, f\"{file_name_without_extension}.txt\")\n",
    "        \n",
    "        with open(best_solution_file_path, 'r') as best_solution_file:\n",
    "            best_solution_lines = best_solution_file.readlines()\n",
    "            all_routes_first_version = json.loads(best_solution_lines[0].strip())\n",
    "        \n",
    "        total_distance = result_distance_dict.get(file_name_without_extension, None)\n",
    "\n",
    "        try:\n",
    "            with open(result_file_path, 'r') as result_file:\n",
    "                lines = [line.strip() for line in result_file.readlines() if line.strip()]\n",
    "\n",
    "            result_data = []\n",
    "            for i in range(0, len(lines), 3):\n",
    "                if i + 2 < len(lines): \n",
    "                    run_time_line = lines[i]\n",
    "                    all_routes_line = lines[i + 1]\n",
    "                    total_distance_line = lines[i + 2]\n",
    "\n",
    "                    run_time = int(run_time_line.split(\":\")[1].strip())\n",
    "                    all_routes = json.loads(all_routes_line.split(\":\")[1].strip())\n",
    "                    total_distance_value = float(total_distance_line.split(\":\")[1].strip())\n",
    "\n",
    "                    result_data.append([run_time, all_routes, total_distance_value])\n",
    "\n",
    "            result_data.append([0, all_routes_first_version, total_distance])\n",
    "\n",
    "            output_file_path = os.path.join(destination_path, file_name)\n",
    "\n",
    "            with open(output_file_path, 'w') as output_file:\n",
    "                for run_time, all_routes, total_distance_value in result_data:\n",
    "                    output_file.write(f\"Run Time: {run_time}\\n\")\n",
    "                    output_file.write(f\"All Routes: {json.dumps(all_routes)}\\n\")\n",
    "                    output_file.write(f\"Total Distance: {total_distance_value}\\n\\n\")\n",
    "\n",
    "            print(f\"Processed file saved to: {output_file_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "file_path = '/home/wsl/CVRPTW/data/test_data_100/c109.txt' \n",
    "with open(file_path, 'r') as file:\n",
    "    data0 = file.read()\n",
    "\n",
    "data = []\n",
    "for line in data0.strip().split('\\n'):\n",
    "    data.append(line.split())\n",
    "\n",
    "columns = [\"CUST\", \"XCOORD.\", 'YCOORD.', 'DEMAND', 'READY', 'DUE', 'SERVICE']\n",
    "df = pd.DataFrame(data[9:], columns=columns)\n",
    "\n",
    "numeric_cols = ['CUST', 'XCOORD.', 'YCOORD.', 'DEMAND', 'READY', 'DUE', 'SERVICE']\n",
    "df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "df['sum'] = df['DUE'] - df['READY']\n",
    "print(np.mean(df['sum']))\n",
    "\n",
    "plt.title(f'Time window distribution of C109')\n",
    "plt.barh(df.index, df['DUE'] - df['READY'], left=df['READY'], color='blue', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(df.loc[1:, 'XCOORD.'], df.loc[1:, 'YCOORD.'], label='Customers', marker='o', color='blue')\n",
    "plt.scatter(df.loc[0, 'XCOORD.'], df.loc[0, 'YCOORD.'], label='Depot', marker='x', color='red')\n",
    "for i, row in df.iterrows():\n",
    "    plt.annotate(row['CUST'], (row['XCOORD.'], row['YCOORD.']), textcoords=\"offset points\", xytext=(0, 5), ha='center')\n",
    "plt.title(f'Customer and Depot Locations of C109')\n",
    "plt.xlabel('X Coordinate')\n",
    "plt.ylabel('Y Coordinate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "file_name = \"r211\"\n",
    "file_path = f'/home/wsl/CVRPTW/data/test_data_100/{file_name}.txt'\n",
    "with open(file_path, 'r') as file:\n",
    "    data0 = file.read()\n",
    "\n",
    "data = []\n",
    "for line in data0.strip().split('\\n'):\n",
    "    data.append(line.split())\n",
    "\n",
    "columns = [\"CUST\", \"XCOORD.\", 'YCOORD.', 'DEMAND', 'READY', 'DUE', 'SERVICE']\n",
    "df = pd.DataFrame(data[9:], columns=columns)\n",
    "\n",
    "numeric_cols = ['CUST', 'XCOORD.', 'YCOORD.', 'DEMAND', 'READY', 'DUE', 'SERVICE']\n",
    "df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "df['sum'] = df['DUE'] - df['READY']\n",
    "print(np.mean(df['sum']))\n",
    "\n",
    "plt.title(f'Time window distribution of {file_name}')\n",
    "plt.barh(df.index, df['DUE'] - df['READY'], left=df['READY'], color='blue', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(df.loc[1:, 'XCOORD.'], df.loc[1:, 'YCOORD.'], label='Customers', marker='o', color='blue')\n",
    "plt.scatter(df.loc[0, 'XCOORD.'], df.loc[0, 'YCOORD.'], label='Depot', marker='x', color='red')\n",
    "for i, row in df.iterrows():\n",
    "    plt.annotate(row['CUST'], (row['XCOORD.'], row['YCOORD.']), textcoords=\"offset points\", xytext=(0, 5), ha='center')\n",
    "plt.title(f'Customer and Depot Locations of {file_name}')\n",
    "plt.xlabel('X Coordinate')\n",
    "plt.ylabel('Y Coordinate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "file_name = \"rc203\"\n",
    "file_path = f'/home/wsl/CVRPTW/data/test_data_100/{file_name}.txt' \n",
    "with open(file_path, 'r') as file:\n",
    "    data0 = file.read()\n",
    "\n",
    "data = []\n",
    "for line in data0.strip().split('\\n'):\n",
    "    data.append(line.split())\n",
    "\n",
    "columns = [\"CUST\", \"XCOORD.\", 'YCOORD.', 'DEMAND', 'READY', 'DUE', 'SERVICE']\n",
    "df = pd.DataFrame(data[9:], columns=columns)\n",
    "\n",
    "numeric_cols = ['CUST', 'XCOORD.', 'YCOORD.', 'DEMAND', 'READY', 'DUE', 'SERVICE']\n",
    "df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "df['sum'] = df['DUE'] - df['READY']\n",
    "print(np.mean(df['sum']))\n",
    "\n",
    "plt.title(f'Time window distribution of {file_name}')\n",
    "plt.barh(df.index, df['DUE'] - df['READY'], left=df['READY'], color='blue', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(df.loc[1:, 'XCOORD.'], df.loc[1:, 'YCOORD.'], label='Customers', marker='o', color='blue')\n",
    "plt.scatter(df.loc[0, 'XCOORD.'], df.loc[0, 'YCOORD.'], label='Depot', marker='x', color='red')\n",
    "for i, row in df.iterrows():\n",
    "    plt.annotate(row['CUST'], (row['XCOORD.'], row['YCOORD.']), textcoords=\"offset points\", xytext=(0, 5), ha='center')\n",
    "plt.title(f'Customer and Depot Locations of {file_name}')\n",
    "plt.xlabel('X Coordinate')\n",
    "plt.ylabel('Y Coordinate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xinference",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
